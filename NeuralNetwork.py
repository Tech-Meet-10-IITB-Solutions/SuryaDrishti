# -*- coding: utf-8 -*-
"""B76 | ISRO.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/150GZQbc2XUChvhk2GK2HE4i9NN8rwvcQ
"""

# Commented out IPython magic to ensure Python compatibility.
#Imports all the required dependencies
import matplotlib #Hasn't been used explicitly. Can be used for data visualisation when needed
import matplotlib.pyplot as plt
import numpy as np
from scipy.interpolate import CubicSpline
from scipy.optimize import curve_fit
from scipy.special import erf
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LeakyReLU
from keras.models import load_model
# %matplotlib inline

n = 10

class ML():
#n denotes the number of light curve data points
  def __init__(self, n):
    self.n = n
    self.model = Sequential()   
    self.model.add(Dense(128, input_dim=3*n + 3))
    self.model.add(LeakyReLU(alpha = 0.1))
    self.model.add(Dense(128))
    self.model.add(LeakyReLU(alpha = 0.1))
    self.model.add(Dense(1, activation='sigmoid')) 
    self.model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) 
    self.model.summary() #Provides the summary of the model. Can be commented out. 

  def forward(self, input):
    output = self.model(input)
    return output

  def train(self, training_data, labeled_data, epochs):
    #training_data is a column matrix of shape (number of data points, 3n + 3)
    history = self.model.fit(training_data, labeled_data, epochs = epochs, verbose = 1) 
    #verbose provides progress bar. Can be set to 0 if no info needs to be displayed.
    return history

  def save(self, path_loc):
    self.model.save(path_loc, optimizer = True, save_format = 'h5')
  
  def load(self, path_loc):
    del self.model
    self.model = load_model(path_loc)

  def imputate(self, raw_data): #raw_data is a an array of shape (2, n) i.e. we have n pairs of (time, counts)
    d_indices = []
    for i in range(self.n):
      if raw_data[1][i] == None:
        d_indices.append(i)
      pprocessed_data = np.zeros((2, self.n - len(d_indices)))  
      pprocessed_data[0] = np.delete(raw_data[0], d_indices)
      pprocessed_data[1] = np.delete(raw_data[1], d_indices)
    spline = CubicSpline(pprocessed_data[0], pprocessed_data[1], extrapolate = True)
    processed_data = np.zeros((2, self.n))
    processed_data[0] = raw_data[0]
    for i in range(len(processed_data[0])):
      processed_data[1][i] = spline(processed_data[0][i])
    return processed_data

  def EFP(self, A, B, C, D, start_time, end_time):
    Z = (2*B + C**2*D)/(2*C)
    x = np.linspace(start_time, end_time, num = self.n, endpoint = True)
    EFP_output =  1/2 * np.sqrt(np.pi) *  A * C * np.exp(D*(B-x) + C**2*D**2/4) * (erf(Z) - erf(Z - x/C))
    return EFP_output

  def train_prep(self, raw_data, parameters_ns, parameters_lm, epochs):
    A_ns, B_ns, C_ns, D_ns, start_time_ns, end_time_ns = parameters_ns
    A_lm, B_lm, C_lm, D_lm, start_time_lm, end_time_lm = parameters_lm
    processed_data = self.imputate(raw_data)
    ns_data = self.EFP(A_ns, B_ns, C_ns, D_ns, start_time_ns, end_time_ns)
    lm_data = self.EFP(A_lm, B_lm, C_lm, D_lm, start_time_lm, end_time_lm)
    training_data = np.concatenate(processed_data, ns_data, lm_data, axis = 0)
    history = self.train(training_data, labeled_data, epochs)
    return history

NN = ML(n)

training_data = np.random.rand(100, 303)
labeled_data = np.random.randint(0, 2, (100, 1))

history = NN.train(training_data, labeled_data, 20)
acc = history.history['accuracy']

output = NN.forward(training_data)
print(output)

#raw_data = np.random.rand(2, n)
raw_data = np.array([[0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],[5, None, 10, 6, None, 9, 1, None, 0, 2.5]])
#raw_data = np.sort(raw_data)
plt.plot(raw_data[0], raw_data[1], marker = 'o')
plt.show()

processed_data = NN.imputate(raw_data)
plt.plot(processed_data[0], processed_data[1], marker = 'o')
plt.show()